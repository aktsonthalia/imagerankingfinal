{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The get_images() function in scraper.py fetches 'N' examples from the \n",
    "web. This dataset is part of the one used by the original paper. It was obtained from: \n",
    "https://sites.google.com/site/imagesimilaritydata/\n",
    "The text file obtained from the above website contains URLs that the images can be \n",
    "retrieved from.\n",
    "Please set 'N' to your desired value, and uncomment the last line in order to\n",
    "retrieve the images from the web.\"\"\"\n",
    "\n",
    "N = 5000\n",
    "\n",
    "# get_images('./urls.txt', N, './images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm._instances.clear()\n",
    "# device = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_model(dir, dims, partition, train_size, n_epochs):\n",
    "    \n",
    "    M, N = partition\n",
    "    train_size = int(train_size * (N - M))\n",
    "    dataset = ImageDataset(dir, dims, range=partition)\n",
    "    train_set = dataset[:train_size]\n",
    "    test_set = dataset[train_size:]\n",
    "    train(model, train_set, test_set, optimizer, n_epochs=5)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [08:22<00:00,  1.26s/it]\n",
      "  0%|          | 1/400 [00:00<00:54,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed. Loss: 0.17619875073432922\n",
      "Evaluating training set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:47<00:00,  8.39it/s]\n",
      "  1%|          | 1/82 [00:00<00:11,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 samples in total. Correctly identified: 265, accuracy: 0.662\n",
      "Evaluating test set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:11<00:00,  7.24it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 samples in total. Correctly identified: 48, accuracy: 0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [10:13<00:00,  1.53s/it]\n",
      "  0%|          | 1/400 [00:00<00:54,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed. Loss: 0.15745626389980316\n",
      "Evaluating training set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:48<00:00,  8.21it/s]\n",
      "  2%|▏         | 2/82 [00:00<00:04, 17.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 samples in total. Correctly identified: 281, accuracy: 0.703\n",
      "Evaluating test set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:09<00:00,  8.37it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 samples in total. Correctly identified: 50, accuracy: 0.610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 196/400 [04:46<05:53,  1.73s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"Creating an instance of the neural network and trasferring it to GPU (if available)\"\"\"\n",
    "\n",
    "\"\"\"Uncomment the code lines below to train the model further. Comment out line 6 in order to\n",
    "prevent it from loading pre-trained parameters.\"\"\"\n",
    "\n",
    "PARTITION = (500, 1000)\n",
    "TRAIN_SIZE = 0.8\n",
    "DIMS = (224, 224)\n",
    "\n",
    "model = network()\n",
    "model = model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('params')) # line 6\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05)\n",
    "\n",
    "\n",
    "\"\"\"Use this line to train the network further\"\"\"\n",
    "train_model('./images', DIMS, PARTITION, TRAIN_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'params')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
