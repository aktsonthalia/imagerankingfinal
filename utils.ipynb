{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING LIBRARIES\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image \n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch import dist\n",
    "from torch import nn\n",
    "from torch.nn import functional as f\n",
    "from torch import optim\n",
    "from torchvision.transforms import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scraper import *\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The get_images() function in scraper.py fetches 'N' examples from the \n",
    "web. This dataset is part of the one used by the original paper. It was obtained from: \n",
    "https://sites.google.com/site/imagesimilaritydata/\n",
    "The text file obtained from the above website contains URLs that the images can be \n",
    "retrieved from.\n",
    "Please set 'N' to your desired value, and uncomment the last line in order to\n",
    "retrieve the images from the web.\"\"\"\n",
    "\n",
    "N = 5000\n",
    "\n",
    "# get_images('./urls.txt', N, './images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function takes an image file, opens it as a PIL Image, resizes it to the \n",
    "   desired dimensions and finally converts it, first into a numpy array, \n",
    "   then a torch tensor.\"\"\"\n",
    "\n",
    "def tensor_from_image(path, dims):\n",
    "    \n",
    "    image = Image.open(path) \n",
    "    image = Resize(dims)(image)\n",
    "    imagematrix = np.asarray(image) \n",
    "    \n",
    "    if(len(imagematrix.shape) != 3):\n",
    "        return None\n",
    "    \n",
    "    imagematrix = np.transpose(imagematrix, (2, 0, 1))\n",
    "    imagetensor = torch.from_numpy(imagematrix)\n",
    "    imagetensor = imagetensor.float()\n",
    "    \n",
    "    return imagetensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"This class defines the image dataset./images/ill be using for training.\n",
    "   The dataset consists of triplets (query, positive, negative)\n",
    "   where the 'positive' image is more similar to the 'query' image \n",
    "   than the negative image is.\n",
    "   Each sample in this dataset is a dictionary containing these three tensors.\"\"\"\n",
    "\n",
    "class ImageDataset:    \n",
    "        \n",
    "    def __init__(self, source_dir, dims, range=(0, 500)):\n",
    "        \n",
    "        dirs = os.listdir(source_dir)\n",
    "        dirs = dirs[range[0] : range[1]]\n",
    "        samples = []\n",
    "        \n",
    "        for i, dir in enumerate(dirs):\n",
    "            \n",
    "            sample = {}\n",
    "            sample['name'] = dir\n",
    "            \n",
    "            q_imagefile = os.path.join(source_dir, dir, 'q.png')\n",
    "            p_imagefile = os.path.join(source_dir, dir, 'p.png')\n",
    "            n_imagefile = os.path.join(source_dir, dir, 'n.png')\n",
    "\n",
    "            sample['query'] = tensor_from_image(q_imagefile, dims)\n",
    "            sample['pos'] = tensor_from_image(p_imagefile, dims)\n",
    "            sample['neg'] = tensor_from_image(n_imagefile, dims)\n",
    "            \n",
    "            if(sample['query'] is None or sample['pos'] is None or sample['neg'] is None):\n",
    "                continue\n",
    "            \n",
    "            samples.append(sample)\n",
    "        \n",
    "        self.samples = samples\n",
    "        self.size = len(samples)\n",
    "        self.dims = dims\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for sample in self.samples:\n",
    "            for category in ['query', 'pos', 'neg']:\n",
    "                N, H, W = sample[category].size()\n",
    "                sample[category] = sample[category].view((1, N, H, W))\n",
    "            yield sample\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "    \n",
    "    def display(self, idx):\n",
    "        _, ax = plt.subplots(1, 3, figsize=(15, 15))\n",
    "        images = []\n",
    "        sample = self.samples[idx]\n",
    "        for i, category in enumerate(['query', 'pos', 'neg']):\n",
    "            imagetensor = sample[category]\n",
    "            imagetensor = imagetensor.cpu()\n",
    "            imagematrix = imagetensor.numpy()\n",
    "            imagematrix = np.transpose(imagematrix, (1, 2, 0))\n",
    "            imagematrix = np.int32(imagematrix)\n",
    "            ax[i].imshow(imagematrix)\n",
    "            \n",
    "            \n",
    "\"\"\"Please uncomment the lines below to test a sample execution of this class\n",
    "(Select the concerned lines and press Ctrl + '/')\"\"\"\n",
    "clear_output()\n",
    "\n",
    "# EXAMPLE USAGE\n",
    "\n",
    "# dataset = ImageDataset('./images', (224, 224))\n",
    "# print(\"Total: {}\".format(dataset.size))\n",
    "# dataset.display(0)\n",
    "# sample = dataset[0]\n",
    "# q, p, n = sample['query'], sample['pos'], sample['neg']\n",
    "# print(q.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"This function defines the triplet ranking loss as used in the original paper.\n",
    "Concretely, given three images (query, positive, negative), it provides a measure of\n",
    "the effectiveness (or more precisely, lack thereof) of the model in\n",
    "identifying that the 'positive' is more closely related to the 'query' \n",
    "than the 'negative'\n",
    "Mathematically, it is defined as:\n",
    "L (q, p, n) = max(0, g + dist(a, p) - dist(a, n))\n",
    "'g' here is a margin, whose value can be set depending on how large of a distinction\n",
    "is desired as ideal between the 'positive' and the 'negative' images\n",
    "\n",
    "The code for this function was borrowed from a PyTorch Discussion Forum\"\"\"\n",
    "\n",
    "def triple_loss(q, p, n, g=0.2) : \n",
    "    dist_function = nn.PairwiseDistance(p=2)\n",
    "    distance = dist_function(q, p) - dist_function(q, n) + g \n",
    "    loss = torch.mean(torch.max(distance, torch.zeros_like(distance))) \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"This function evaluates the model on a given dataset. The model is \n",
    "considered to have done its job on a particular sample correctly if\n",
    "dist(query, positive) is less than dist(query, negative), \n",
    "subsequently implying that 'positive' is more similar to 'query'\n",
    "than 'negative' is.\n",
    "\n",
    "The distance computations are done after the image tensors have been passed \n",
    "through the model\"\"\"\n",
    "\n",
    "def evaluate(model, samples):\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for sample in tqdm(samples):\n",
    "\n",
    "        q, p, n = sample['query'], sample['pos'], sample['neg']   \n",
    "        N, H, W = q.size()\n",
    "        q = q.view((1, N, H, W))\n",
    "        p = p.view((1, N, H, W))\n",
    "        n = n.view((1, N, H, W))\n",
    "        \n",
    "        q, p, n = q.to(device), p.to(device), n.to(device)\n",
    "        \n",
    "        q = model(q)\n",
    "        p = model(p)\n",
    "        n = model(n)\n",
    "\n",
    "        dist = nn.PairwiseDistance(p=2)\n",
    "        if(dist(q, p) < dist(q, n)):\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    \n",
    "    print(\"{} samples in total. Correctly identified: {}, accuracy: {:.3f}\".format(total, correct, correct/total))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(model, train_set, test_set, optimizer, loss_function=triple_loss, \n",
    "          n_epochs=1):\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        total_loss = 0\n",
    "        for sample in tqdm(train_set):\n",
    "            q = sample['query']\n",
    "            p = sample['pos']\n",
    "            n = sample['neg']\n",
    "            q, p, n = q.to(device), p.to(device), n.to(device)\n",
    "            \n",
    "            N, H, W = q.size()\n",
    "            q = q.view((1, N, H, W))\n",
    "            p = p.view((1, N, H, W))\n",
    "            n = n.view((1, N, H, W))\n",
    "            \n",
    "            q = model(q)\n",
    "            p = model(p)\n",
    "            n = model(n)\n",
    "            \n",
    "            loss = triple_loss(q, p, n)\n",
    "            loss.backward(retain_graph=False)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss\n",
    "                \n",
    "        print(\"Epoch {} completed. Loss: {}\".format(i+1, total_loss / len(train_set)))\n",
    "        print(\"Evaluating training set:\")\n",
    "        evaluate(model, train_set)\n",
    "        print(\"Evaluating test set:\")\n",
    "        evaluate(model, test_set)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"This class defines the model we will be training and using for our ranking\n",
    "task. The model consists of three smaller convolutional networks, whose outputs are\n",
    "to be concatenated to produce a final feature vector. Details of the network can\n",
    "be found in the following paper:\n",
    "http://wangjiangb.github.io/pdfs/deep_ranking.pdf\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        \"\"\"The code for AlexNet was borrowed from the PyTorch Documentation\"\"\"\n",
    "        self.alexnet = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.AdaptiveAvgPool2d((6, 6)),\n",
    "            nn.Dropout(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(9216, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.shallow1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 3, kernel_size=3, stride=4, padding=2),\n",
    "            nn.Conv2d(3, 96, kernel_size=8, padding=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=4),\n",
    "            nn.Conv2d(96, 96, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),            \n",
    "        )\n",
    "        \n",
    "        self.shallow2 = nn.Sequential(\n",
    "            nn.Conv2d(3, 3, kernel_size=3, stride=8, padding=2),\n",
    "            nn.Conv2d(3, 96, kernel_size=8, padding=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=4),\n",
    "            nn.Conv2d(96, 96, kernel_size=7, padding=7),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=4),\n",
    "            nn.Flatten(),            \n",
    "        )\n",
    "        \n",
    "        self.embedding = nn.Linear(7168, 4096)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.alexnet(x)\n",
    "        x1 = nn.functional.normalize(x1, p=2, dim=1)\n",
    "        \n",
    "        \n",
    "#         x2 = nn.functional.interpolate(x, size=57)\n",
    "        x2 = self.shallow1(x)\n",
    "        \n",
    "#         x3 = nn.functional.interpolate(x, size=29)\n",
    "        x3 = self.shallow2(x)\n",
    "        \n",
    "        x4 = torch.cat((x2, x3), 1)\n",
    "        x4 = nn.functional.normalize(x4, p=2, dim=1)\n",
    "        \n",
    "        x5 = torch.cat((x1, x4), 1)\n",
    "        \n",
    "        x5 = self.embedding(x5)\n",
    "        x5 = nn.functional.normalize(x5, p=2, dim=1)\n",
    "        \n",
    "#         x5 = x5.view((x5.size(1)))\n",
    "        return x5\n",
    "        \n",
    "#         return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
